---
title: "Colorado COVID-19: CDC API Analysis (Cache-First)"
format:
  html:
    theme: flatly
    toc: true
    code-fold: show
    df-print: paged
  pdf: default
execute:
  echo: true
  warning: true
  message: true
---

```{r setup, include=FALSE}
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(lubridate); library(ggplot2)
  library(httr); library(jsonlite); library(tibble); library(purrr)
  library(readr); library(scales); library(stringr)
})

options(timeout = 60)  # cap any single HTTP call
set.seed(1)

# ------------------------------------------------------------
# Paths — this QMD is in scripts/, cache directory is at repo root
# ------------------------------------------------------------
CACHE_DIR <- normalizePath(file.path("..", "cache"), mustWork = FALSE)
if (!dir.exists(CACHE_DIR)) dir.create(CACHE_DIR, recursive = TRUE, showWarnings = FALSE)

cp <- function(name) file.path(CACHE_DIR, name)              # cache path helper
cache_exists <- function(name) file.exists(cp(name))
cache_read   <- function(name) readRDS(cp(name))
cache_write  <- function(obj, name) saveRDS(obj, cp(name))

message("Using cache dir: ", CACHE_DIR)

# ------------------------------------------------------------
# Token helpers
# ------------------------------------------------------------
get_token <- function() trimws(Sys.getenv("SOCRATA_APP_TOKEN_CDC", ""))
need_token <- function() nzchar(get_token())

require_token <- function() {
  if (!need_token()) {
    stop(
"CDC token missing.

Set it once (recommended) in ~/.Renviron and restart R:

  SOCRATA_APP_TOKEN_CDC=your_long_token_here

Then re-run this document. If all cache files already exist in ../cache/,
no token is required.",
      call. = FALSE
    )
  }
}

# ------------------------------------------------------------
# Robust CDC fetchers (param-style SODA with RETRY/backoff)
# ------------------------------------------------------------
cdc_fetch2 <- function(
  url_base = "https://data.cdc.gov/resource/n8mc-b4w4.json",
  query = list(),
  token_env = "SOCRATA_APP_TOKEN_CDC",
  total_timeout_sec = 120,
  tries = 6
) {
  tok <- trimws(Sys.getenv(token_env, ""))
  hdr <- if (nzchar(tok)) add_headers("X-App-Token" = tok) else NULL

  resp <- RETRY("GET", url_base, hdr,
                query = query,
                user_agent("colorado-covid-quarto/1.0"),
                timeout(total_timeout_sec),
                times = tries, pause_base = 1, pause_cap = 15)

  # if auth failure, try $$app_token in the query (in case headers are stripped)
  if (status_code(resp) %in% c(401,403) && nzchar(tok)) {
    resp <- RETRY("GET", url_base,
                  query = c(query, `$$app_token` = tok),
                  user_agent("colorado-covid-quarto/1.0"),
                  timeout(total_timeout_sec),
                  times = tries, pause_base = 1, pause_cap = 15)
  }

  raw <- content(resp, as = "raw")
  txt <- if (length(raw)) { x <- rawToChar(raw); Encoding(x) <- "UTF-8"; x } else ""
  if (http_error(resp)) {
    stop(sprintf("CDC API HTTP %s after retries. First 300 chars:\n%s",
                 status_code(resp), substr(txt, 1, 300)), call. = FALSE)
  }
  tryCatch(fromJSON(txt, simplifyVector = TRUE),
           error = function(e) stop(sprintf("JSON parse failed. First 300:\n%s",
                                            substr(txt, 1, 300)), call. = FALSE)) |>
    as_tibble()
}

# Build $select/$where/$group/$order safely (no SQL keywords in strings)
cdc_select <- function(select, where=NULL, group=NULL, order=NULL, limit=NULL,
                       token_env = "SOCRATA_APP_TOKEN_CDC") {
  clean <- function(x, which) {
    if (is.null(x) || !nzchar(x)) return("")
    pat <- switch(which,
      select = "^\\s*(?i)select\\s+",
      where  = "^\\s*(?i)where\\s+",
      group  = "^\\s*(?i)group\\s+by\\s+",
      order  = "^\\s*(?i)order\\s+by\\s+"
    )
    sub(pat, "", x, perl = TRUE)
  }
  q <- list(`$select` = clean(select, "select"))
  w <- clean(where, "where"); if (nzchar(w)) q$`$where` <- w
  g <- clean(group, "group"); if (nzchar(g)) q$`$group` <- g
  o <- clean(order, "order"); if (nzchar(o)) q$`$order` <- o
  if (!is.null(limit)) q$`$limit` <- as.integer(limit)
  cdc_fetch2(query = q, token_env = token_env)
}

label_si_safe <- function() {
  if ("label_number_si" %in% getNamespaceExports("scales")) {
    scales::label_number_si()
  } else {
    scales::comma
  }
}
```

## Inputs & cache strategy

This analysis reads pre-computed aggregates from `../cache/`.\
If a file is missing, it will fetch the minimal slice from CDC and write it, so subsequent runs are fast and offline.

```{r cache-plan}
required_files <- c(
  "co_month.rds",
  "co_by_age.rds",
  # county×month: one file per year, we'll detect what's missing dynamically
  "co_county.rds",
  "severe.rds"
)

existing <- file.exists(file.path(CACHE_DIR, required_files))
tibble(file = required_files, exists = existing)
```

## Build or load: Monthly totals for Colorado

```{r build-co-month}
if (!cache_exists("co_month.rds")) {
  require_token()
  message("Fetching co_month …")
  co_month <- cdc_select(
    select = "case_month, count(1) as n",
    where  = "res_state = 'CO'",
    group  = "case_month",
    order  = "case_month",
    limit  = 5000
  ) |>
    mutate(case_month = as.Date(paste0(case_month, "-01")),
           n = as.numeric(n))
  cache_write(co_month, "co_month.rds")
} else {
  co_month <- cache_read("co_month.rds")
}
summary(co_month)
```

## Build or load: Monthly by age group

```{r build-by-age}
if (!cache_exists("co_by_age.rds")) {
  require_token()
  message("Fetching co_by_age …")
  co_by_age <- cdc_select(
    select = "case_month, age_group, count(1) as n",
    where  = "res_state = 'CO' AND age_group IS NOT NULL AND age_group <> 'Missing'",
    group  = "case_month, age_group",
    order  = "case_month, age_group",
    limit  = 50000
  ) |>
    mutate(case_month = as.Date(paste0(case_month, "-01")),
           n = as.numeric(n))
  cache_write(co_by_age, "co_by_age.rds")
} else {
  co_by_age <- cache_read("co_by_age.rds")
}
summary(co_by_age)
```

## County × Month slices (yearly) — load existing, fetch only missing

```{r build-county-month}
#| label: build-county-month
# County × Month slices (yearly) — load existing, fetch only missing (robust to empty years)

# Use co_month to cap the year range to what's actually available
year_start <- 2020L
last_month <- max(co_month$case_month, na.rm = TRUE)
year_end   <- lubridate::year(last_month)
target_years <- seq.int(year_start, year_end)

year_files   <- sprintf("co_county_month_%d.rds", target_years)
missing_years <- target_years[!file.exists(file.path(CACHE_DIR, year_files))]

# Helper: fetch one year's slice; return a typed-empty tibble if API returns []
fetch_county_month_year <- function(y) {
  df <- cdc_select(
    select = "case_month, county_fips_code, count(1) as n",
    where  = sprintf("res_state = 'CO' AND county_fips_code IS NOT NULL AND case_month between '%d-01' and '%d-12'", y, y),
    group  = "case_month, county_fips_code",
    limit  = 120000
  )

  # If the API returns zero rows or missing columns, create a typed-empty tibble
  if (nrow(df) == 0L || !all(c("case_month","county_fips_code","n") %in% names(df))) {
    message("No rows for year ", y, " — skipping (dataset likely ends before this year).")
    return(tibble::tibble(
      case_month       = as.Date(character()),
      county_fips_code = character(),
      n                = numeric()
    ))
  }

  df |>
    dplyr::mutate(
      case_month       = as.Date(paste0(case_month, "-01")),
      county_fips_code = sprintf("%05s", county_fips_code),
      n                = suppressWarnings(as.numeric(n))
    )
}

# Fetch only the missing years (if any)
if (length(missing_years)) {
  require_token()
  message("Fetching county×month slices for: ", paste(missing_years, collapse = ", "))
  for (y in missing_years) {
    df_y <- fetch_county_month_year(y)
    cache_write(df_y, sprintf("co_county_month_%d.rds", y))
  }
}

# Bind all available yearly slices from cache
yr_files <- list.files(CACHE_DIR, pattern = "^co_county_month_\\d{4}\\.rds$", full.names = TRUE)

if (length(yr_files) == 0L) {
  warning("No county-month cache files found after fetch; proceeding with an empty frame.")
  co_county_month <- tibble::tibble(
    case_month       = as.Date(character()),
    county_fips_code = character(),
    n                = numeric()
  )
} else {
  co_county_month <- purrr::map_dfr(yr_files, readRDS) |>
    dplyr::mutate(
      case_month       = as.Date(case_month),
      county_fips_code = sprintf("%05s", county_fips_code),
      n                = suppressWarnings(as.numeric(n))
    ) |>
    dplyr::arrange(case_month, county_fips_code)
}

summary(co_county_month)

```

## County totals — derive locally from county × month, then join names

```{r build-co-county}
# Use cache if present; otherwise derive and save
if (cache_exists("co_county.rds")) {
  co_county <- cache_read("co_county.rds")
} else {
  co_county <- co_county_month |>
    group_by(county_fips_code) |>
    summarise(n = sum(n, na.rm = TRUE), .groups = "drop")

  suppressPackageStartupMessages({ library(sf); library(tigris) })
  options(tigris_use_cache = TRUE)
  co_names <- tigris::counties(state = "CO", year = 2023, class = "sf") |>
    sf::st_drop_geometry() |>
    transmute(county_fips_code = GEOID, res_county = NAME)

  co_county <- co_county |>
    left_join(co_names, by = "county_fips_code") |>
    relocate(res_county, .after = county_fips_code) |>
    arrange(desc(n))

  cache_write(co_county, "co_county.rds")
}
summary(co_county)
```

## Severity proxies (hospitalization & death ratios) — always present

```{r build-severe}
if (!cache_exists("severe.rds")) {
  require_token()
  message("Computing severity ratios (from grouped queries)…")

  count_by_month <- function(where_extra = NULL, limit = 50000) {
    wc <- paste(c("res_state = 'CO'", where_extra), collapse = " AND ")
    cdc_select(
      select = "case_month, count(1) as n",
      where  = wc,
      group  = "case_month",
      order  = "case_month",
      limit  = limit
    ) |>
      mutate(case_month = as.Date(paste0(case_month, "-01")),
             n = as.numeric(n))
  }

  co_total <- count_by_month()
  co_hosp  <- count_by_month("hosp_yn = 'Yes'") |> rename(hosp_n = n)
  co_death <- count_by_month("death_yn = 'Yes'") |> rename(death_n = n)

  severe <- co_total |>
    full_join(co_hosp,  by = "case_month") |>
    full_join(co_death, by = "case_month") |>
    mutate(
      hosp_n     = tidyr::replace_na(hosp_n, 0),
      death_n    = tidyr::replace_na(death_n, 0),
      hosp_rate  = if_else(n > 0, hosp_n / n, NA_real_),
      death_rate = if_else(n > 0, death_n / n, NA_real_)
    ) |>
    arrange(case_month)

  cache_write(severe, "severe.rds")
} else {
  severe <- cache_read("severe.rds")
}
summary(severe)
```

## Quick visuals (sanity checks)

```{r plots, fig.width=8, fig.height=4}
ggplot(co_month, aes(case_month, n)) +
  geom_line(size = 0.8) +
  scale_y_continuous(labels = label_si_safe()) +
  labs(title = "Colorado Monthly Cases", x = NULL, y = "Count") +
  theme_minimal(base_size = 13)
```

```{r by-age-plot, fig.width=8, fig.height=4}
co_by_age |> 
  group_by(case_month) |>
  mutate(pct = n / sum(n)) |>
  ungroup() |>
  ggplot(aes(case_month, pct, fill = age_group)) +
  geom_area(alpha = 0.9) +
  scale_y_continuous(labels = percent) +
  labs(title = "Age distribution by month", x = NULL, y = "Share") +
  theme_minimal(base_size = 13)
```

```{r top-counties, fig.width=8, fig.height=4}
latest_month <- max(co_county_month$case_month, na.rm = TRUE)
co_county_month |>
  filter(case_month == latest_month) |>
  left_join(select(co_county, county_fips_code, res_county), by = "county_fips_code") |>
  slice_max(n, n = 10) |>
  mutate(res_county = forcats::fct_reorder(res_county, n)) |>
  ggplot(aes(res_county, n)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = label_si_safe()) +
  labs(title = paste("Top counties in", format(latest_month, "%Y-%m")),
       x = NULL, y = "Cases") +
  theme_minimal(base_size = 13)
```
